<h1>Results</h1>

When run, the program simulates convection in 3d in much the same way
as @ref step_31 "step-31" did, though with an entirely different testcase.


<h3>Comparison of results with step-31</h3>

Before we go to this testcase, however, let us show a few results from a
slightly earlier version of this program that was solving exactly the
testcase we used in step-31, just that we now solve it in parallel and with
much higher resolution. We show these results mainly for comparison.

Here are two images that show this higher resolution if we choose a 3d
computation in <code>main()</code> and if we set
<code>initial_refinement=3</code> and
<code>n_pre_refinement_steps=4</code>. At the time steps shown, the
meshes had around 72,000 and 236,000 cells, for a total of 2,680,000
and 8,250,000 degrees of freedom, respectively, more than an order of
magnitude more than we had available in step-31:

<table align="center" border="1" cellspacing="3" cellpadding="3">
  <tr>
    <td>
        @image html "step-32.3d.cube.0.png" "" width=80%
    </td>
  </tr>
  <tr>
    <td>
        @image html "step-32.3d.cube.1.png" "" width=80%
    </td>
  </tr>
</table>

The computation was done on a subset of 50 processors of the Brazos
cluster at Texas A&amp;M University.


<h3>Results for a 2d circular shell testcase</h3>


If we run the program as shown above, the output will look roughly like this,
producing the final part of the output after some 2 days when run on 10
processors:

<code>
<pre>
Number of active cells: 12288 (on 6 levels)
Number of degrees of freedom: 162432 (99840+12672+49920)

Timestep 0:  t=0 years
   Assembling...
   Rebuilding Stokes preconditioner...
   Solving...
   14 BiCGStab iterations for Stokes subsystem.
   Maximal velocity: 1.80187 cm/year
   Time step: 607937 years
   15 CG iterations for temperature
   Temperature range: 973 4273.27

Number of active cells: 17988 (on 7 levels)
Number of degrees of freedom: 240504 (147888+18672+73944)

Timestep 0:  t=0 years
   Assembling...
   Rebuilding Stokes preconditioner...
   Solving...
   3 BiCGStab iterations for Stokes subsystem.
   Maximal velocity: 1.52763 cm/year
   Time step: 357565 years
   17 CG iterations for temperature
   Temperature range: 973 4274.08

Number of active cells: 34716 (on 8 levels)
Number of degrees of freedom: 474550 (291896+36706+145948)

Timestep 0:  t=0 years
   Assembling...
   Rebuilding Stokes preconditioner...
   Solving...
   3 BiCGStab iterations for Stokes subsystem.
   Maximal velocity: 2.97931 cm/year
   Time step: 91574.3 years
   17 CG iterations for temperature
   Temperature range: 973 4277.31

Timestep 1:  t=91574.3 years
   Assembling...
   Solving...
   2 BiCGStab iterations for Stokes subsystem.
   Maximal velocity: 2.86431 cm/year
   Time step: 95251.1 years
   18 CG iterations for temperature
   Temperature range: 973 4277.31

[...]

Timestep 53906:  t=9.99985e+08 years
   Assembling...
   Solving...
   4 BiCGStab iterations for Stokes subsystem.
   Maximal velocity: 12.2898 cm/year
   Time step: 22199.6 years
   18 CG iterations for temperature
   Temperature range: 973 4273.07


+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |  1.87e+05s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assemble Stokes system          |     53909 |  1.06e+04s |       5.7% |
| Assemble temperature matrices   |      5393 |       913s |      0.49% |
| Assemble temperature rhs        |     53909 |  1.24e+04s |       6.6% |
| Build Stokes preconditioner     |      5393 |  4.52e+03s |       2.4% |
| Solve Stokes system             |     53909 |  6.94e+04s |        37% |
| Solve temperature system        |     53909 |  2.34e+04s |        13% |
| Postprocessing                  |      2157 |  5.51e+03s |       2.9% |
| Refine mesh structure, part 1   |      5392 |  4.71e+04s |        25% |
| Refine mesh structure, part 2   |      5392 |  1.02e+03s |      0.55% |
| Setup dof systems               |      5393 |  1.11e+04s |       5.9% |
+---------------------------------+-----------+------------+------------+
</pre>
</code>

As can be seen here, we spend most of the compute time in assembling linear
systems, refining the mesh, and in particular in solving the Stokes and
temperature linear systems.

The 50% spent on solving the linear systems are affected in large part
because the Brazos cluster has a relatively slow ethernet interconnect. A
cluster with a faster interconnect, for example using infiniband, should do
better in this regard. On the other hand, there is little hope to do better
with assembling the linear systems, though one could do significantly better
with estimating the error by making sure that each processor only estimates
the error on those cells it owns.


The program writes output every 25th time step, but we won't show all
2100 or so images this produces. Rather, let us only show the output
from every 2500th time step here, even though this does, of course,
not do full justice to the dynamics that are going on:
<table>
  <tr>
    <td>
      @image html step-32.2d.temperature.0000.png
    <td>

    <td>
      @image html step-32.2d.temperature.0100.png
    <td>

    <td>
      @image html step-32.2d.temperature.0200.png
    <td>
  </tr>

  <tr>
    <td>
      @image html step-32.2d.temperature.0300.png
    <td>

    <td>
      @image html step-32.2d.temperature.0400.png
    <td>

    <td>
      @image html step-32.2d.temperature.0500.png
    <td>
  </tr>

  <tr>
    <td>
      @image html step-32.2d.temperature.0600.png
    <td>

    <td>
      @image html step-32.2d.temperature.0700.png
    <td>

    <td>
      @image html step-32.2d.temperature.0800.png
    <td>
  </tr>

  <tr>
    <td>
      @image html step-32.2d.temperature.0900.png
    <td>

    <td>
      @image html step-32.2d.temperature.1000.png
    <td>

    <td>
      @image html step-32.2d.temperature.1100.png
    <td>
  </tr>

  <tr>
    <td>
      @image html step-32.2d.temperature.1200.png
    <td>

    <td>
      @image html step-32.2d.temperature.1300.png
    <td>

    <td>
      @image html step-32.2d.temperature.1400.png
    <td>
  </tr>

  <tr>
    <td>
      @image html step-32.2d.temperature.1500.png
    <td>

    <td>
      @image html step-32.2d.temperature.1600.png
    <td>

    <td>
      @image html step-32.2d.temperature.1700.png
    <td>
  </tr>

  <tr>
    <td>
      @image html step-32.2d.temperature.1800.png
    <td>

    <td>
      @image html step-32.2d.temperature.1900.png
    <td>

    <td>
      @image html step-32.2d.temperature.2000.png
    <td>
  </tr>


  <tr>
    <td>
      @image html step-32.2d.temperature.2100.png
    <td>

    <td>
      @image html step-32.2d.grid.2100.png
    <td>

    <td>
      @image html step-32.2d.partition.2100.png
    <td>
  </tr>
</table>

The last two images show the grid as well as the partitioning of the
mesh for the last timestep shown into the 10 subdomains used for this
computation. The full dynamics are really only visible by looking at
an animation. <a
href="http://www.math.tamu.edu/~bangerth/images/pictures/convection-outward/step-32.2d.convection.gif">At
this site</a> is such an animation. Beware that this animation is
about 20MB large, though it is well worth watching due to its almost
artistic quality.

If you watch the movie, you'll see that the convection pattern goes
through several stages: First, it gets rid of the instable temperature
layering with the hot material overlaid by the dense cold
material. After this great driver is removed and we have a sort of
stable situation, a few blobs start to separate from the hot boundary
layer at the inner ring and rise up, with a few cold fingers also
dropping down from the outer ring. During this phase, the solution
remains mostly symmetric, reflecting the 12-fold symmetry of the
original mesh. In a final phase, the fluid enters vigorous chaotic
stirring in which all symmetries are lost. This is a pattern that then
continues to dominate flow.

These different phases can also be identified if we look at the
maximal velocity as a function of time in the simulation:

@image html step-32.2d.t_vs_vmax.png

Here, the velocity (shown in centimeters per year) becomes very large,
to the order of several meters per year) at the beginning when the
temperature layering is instable. It then calms down to relatively
small values before picking up again in the chaotic stirring
regime. There, it remains in the range of 10-40 centimeters per year,
quite within the physically expected region.



<a name="extensions"></a>
<h3>Possibilities for extensions</h3>

Apart from the various possibilities for extensions already outlined
in the @ref step_31 "step-31", here are a few more ideas:

<ul>
  <li> The temperature field we get in our simulations after a while
  is mostly constant with boundary layers at the inner and outer
  boundary, and streamers of cold and hot material mixing
  everything. Yet, this doesn't match our expectation that things
  closer to the earth core should be hotter than closer to the
  surface. The reason is that the energy equation we have used does
  not include a term that describes adiabatic cooling and heating:
  rock, like gas, heats up as you compress it. Consequently, material
  that rises up cools adiabatically, and cold material that sinks down
  heats adiabatically. The correct temperature equation would
  therefore look somewhat like this:
  @f{eqnarray*}
    \frac{D T}{Dt}
    -
    \nabla \cdot \kappa \nabla T &=& \gamma + \tau\frac{Dp}{Dt},
  @f}
  or, expanding the advected derivative $\frac{D}{Dt} =
  \frac{\partial}{\partial t} + \mathbf u \cdot \nabla$:
  @f{eqnarray*}
    \frac{\partial T}{\partial t}
    +
    {\mathbf u} \cdot \nabla T
    -
    \nabla \cdot \kappa \nabla T &=& \gamma +
    \tau\left\{\frac{\partial
    p}{\partial t} + \mathbf u \cdot \nabla p \right\}.
  @f}
  In other words, as pressure increases in a rock volume
  ($\frac{Dp}{Dt}>0$) we get an additional heat source, and vice
  versa.

  The time derivative of the pressure is a bit awkward to
  implement. If necessary, one could approximate using the fact
  outlined in the introduction that the pressure can be decomposed
  into a dynamic component due to temperature differences and the
  resulting flow, and a static component that results solely from the
  static pressure of the overlying rock. Since the latter is much
  bigger, one may approximate $p\approx p_{\text{static}}=-\rho_{\text{ref}}
  [1+\beta T_{\text{ref}}] \varphi$, and consequently
  $\frac{Dp}{Dt} \approx \left\{- \mathbf u \cdot \nabla \rho_{\text{ref}}
  [1+\beta T_{\text{ref}}]\varphi\right\} = \rho_{\text{ref}}
  [1+\beta T_{\text{ref}}] \mathbf u \cdot \mathbf g$.
  In other words, if the fluid is moving in the direction of gravity
  (downward) it will be compressed and because in that case $\mathbf u
  \cdot \mathbf g > 0$ we get a positive heat source. Conversely, the
  fluid will cool down if it moves against the direction of gravity.

  Implementing this requires one additional step, however. As mentioned in the
  introduction, we use a rather simplified model for gravity in which the
  gravity force diminishes with depth, as if Earth had a homogenous
  density. That isn't the case, however: the earth core is much denser than
  the mantle, and gravity actually tops out at the core
  mantle boundary. A consequence of this is that our computations predict
  pressures around 80 GPa at the core mantle boundary, whereas in reality the
  value is closer to 140 GPa. With a pressure wrong by so much, we can't
  expect compression heating to be accurate.

  A more realistic model for the gravity vector in the program would take the
  spatially variable density into account, and that wouldn't actually be
  terribly complicated: by integrating the PDE for the gravity potential under
  the assumption that $\rho(\mathbf x)=\rho(r)$, we get
  @f[
    \varphi(r) = 4\pi G \int_0^r \frac 1{t^2} \int_0^t s^2 \rho(s) \; ds \; dt,
  @f]
  and consequently for the gravity vector
  @f[
    \mathbf g = - 4\pi G \frac 1{r^2} \left(
      \int_0^r s^2 \rho(s) \; ds \right)
    \frac{\mathbf x}{\|\mathbf x\|}.
  @f]
  This expression reduces to the one we use for the case that the density is
  constant, but a more complete model would, for example, assume that the
  density varies with the radius (in the simplest case it could be constant in
  various layers). In either case, it can relatively easily be evaluated if
  for non-trivial models of $\rho(r)$. Of course, a really complete model
  would consider that $\rho$ can also vary in the tangential direction, for
  example in a time dependent way as a consequence of the thermal expansion of
  rocks as a result of the convection. Taking into account this self
  gravitational effect of convection would be much harder, however.
</ul>
