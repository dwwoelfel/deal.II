<a name="Intro"></a>
<h1>Introduction</h1>

This tutorial program attempts to show how to use $hp$ finite element methods
with deal.II. It solves the Laplace equation and so builds only on the first
few tutorial programs, in particular on @ref step_4 "step-4" for dimension
independent programming and @ref step_6 "step-6" for adaptive mesh
refinement. 

The $hp$ finite element method was proposed in the early 1980s by
Babuska and Guo as an alternative to either
(i) mesh refinement (i.e. decreasing the mesh parameter $h$ in a finite
element computation) or (ii) increasing the polynomial degree $p$ used for
shape functions. It is based on the observation that increasing the polynomial
degree of the shape functions reduces the approximation error if the solution
is sufficiently smooth.  On the other hand, it is well known
that even for the generally well-behaved class of elliptic problems, higher
degrees of regularity can not be guaranteed in the vicinity of boundaries,
corners, or where coefficients are discontinuous; consequently, the
approximation can not be improved in these areas by increasing the polynomial
degree $p$ but only by refining the mesh, i.e. by reducing the mesh size
$h$. These differing means to reduce the 
error have led to the notion of $hp$ finite elements, where the approximating
finite element spaces are adapted to have a high polynomial degree $p$
wherever the solution is sufficiently smooth, while the mesh width $h$ is
reduced at places wherever the solution lacks regularity. It was
already realized in the first papers on this method that $hp$ finite elements
can be a powerful tool that can guarantee that the error is reduced not only
with some negative power of the number of degrees of freedom, but in fact
exponentially.

In order to implement this method, we need several things above and beyond
what a usual finite element program needs, and in particular above what we
have introduced in the tutorial programs leading up to step-6. In particular,
we will have to discuss the following aspects:
<ul>
  <li>Instead of using the same finite element on all cells, we now will want
  a collection of finite element objects, and associate each cell with one
  of these objects in this collection.

  <li>Degrees of freedom will then have to be allocated on each cell depending
  on what finite element is associated with this particular cell. Constraints
  will have to generated in the same way as for hanging nodes, but now also
  including the case where two neighboring cells 

  <li>We will need to 
</ul>


<h3>A simple indicator for smoothness</h3>

One of the central pieces of the adaptive finite element method is that we
inspect the computed solution (a posteriori) with an indicator that tells us
which are the cells where the error is largest, and then refine them. In many
of the other tutorial programs, we use the KellyErrorEstimator class to get an
indication of the size of the error on a cell, although we also discuss more
complicated strategies in some programs, most importantly in @ref step_14 "step-14". 

In any case, as long as the decision is only "refine this cell" or "do not
refine this cell", the actual refinement step is not particularly
challenging. However, here we have a code that is capable of hp refinement,
i.e. we suddenly have two choices whenever we detect that the error on a
certain cell is too large for our liking: we can refine the cell by splitting
it into several smaller ones, or we can increase the polynomial degree of the
shape functions used on it. How do we know which is the more promising
strategy? 

In short, the question does not appear to be settled in the literature at this
time. There are a number of more or less complicated schemes that address it,
but there is nothing like the KellyErrorEstimator that is universally accepted
as a good indicator of the error. Most proposals use the fact that it is
beneficial to increase the polynomial degree whenever the solution is locally
smooth whereas it is better to refine the mesh wherever it is rough. However,
the questions of how to determine the local smoothness of the solution as well
as the decision when a solution is smooth enough to allow for an increase in
$p$ are certainly big and important ones.


<h4>The idea</h4>

We do not intend to enter a sophisticated proposal into the fray about answers
to the general question. However, to demonstrate our approach to hp finite
elements, we need a simple indicator that does generate some useful
information. Our approach here is simple: for a function $u(x)$ to be in the
Sobolev space $H^s(K)$ on a cell $K$, it has to satisfy the condition
@f[
	\int_K |\nabla^s u(x)|^2 \; dx < \infty.
@f]
Assuming that the cell $K$ is not degenerate, i.e. that the mapping from the
unit cell to cell $K$ is sufficiently regular, above condition is of course
equivalent to
@f[
	\int_{\hat K} |\nabla^s \hat u(\hat x)|^2 \; dx < \infty
@f]
where $\hat u(\hat x)$ is the function $u(x)$ mapped back onto the unit cell
$\hat K$. From here, we can do the following: first, let us define the
Fourier series of $\hat u$ as
@f[
	\hat U_{\vec k}
	= \frac 1{(2\pi)^{d/2}} \int_{\hat K} e^{i\vec k \cdot \vec x} \hat u(\hat x) dx
@f]
with Fourier vectors $\vec k=(k_x,k_y)$ in 2d, $\vec k=(k_x,k_y,k_z)$
in 3d, etc, and $k_x,k_y,k_z=0,\pi,2\pi,3\pi,\ldots$. If we re-compose $\hat u$
from $\hat U$ using the formula
@f[
	\hat u(\vec x) 
	= \frac 1{(2\pi)^{d/2}} \sum_{\vec k} e^{-i\vec k \cdot \vec x} \hat U_{\hat k} dx,
@f]
then it becomes clear that we can write the $H^s$ norm of $\hat u$ as
@f[
	\int_K |\nabla^s u(x)|^2 \; dx
	=
	\frac 1{(2\pi)^d}
	\int_K 
	\left|
	  \sum_{\vec k} |\vec k|^s e^{-i\vec k \cdot \vec x} \hat U_{\hat k}
        \right|^2 \; dx
	=
	\sum_{\vec k} 
	  |\vec k|^{2s}
	  |\hat U_{\hat k}|^2.
@f]
In other words, if this norm is to be finite (i.e. for $\hat u(\vec
x)$ to be in $H^s(\hat K)$), we need that
@f[
	|\hat U_{\hat k}| = {\cal O}\left(|\vec k|^{-\left(s+1/2+\frac{d-1}{2}+\epsilon\right)}\right).
@f]
Put differently: the higher regularity $s$ we want, the faster the
Fourier coefficients have to go to zero. (If you wonder where the
additional exponent $\frac{d-1}2$ comes from: we would like to make
use of the fact that $\sum_l a_l < \infty$ if the sequence $a_l =
{\cal O}(l^{-1-\epsilon})$ for any $\epsilon>0$. The problem is that we
here have a summation not only over a single variable, but over all
the integer multiples of $\pi$ that are located inside the
$d$-dimensional sphere, because we have vector components $k_x, k_y,
\ldots$. In the same way as we prove that the sequence $a_l$ above
converges by replacing the sum by an integral over the entire line, we
can replace our $d$-dimensional sum by an integral over
$d$-dimensional space. Now we have to note that between distance $|k|$
and $|k|+d|k|$, there are, up to a constant, $|k|^{d-1}$ modes, in
much the same way as we can transform the volume element $dx\;dy$ into
$2\pi r\; dr$. Consequently, it is no longer $|\vec k|^{2s}|\hat
U_{\hat k}|^2$ that has to decay as ${\cal O}(k^{-1-\epsilon})$, but
it is in fact $|\vec k|^{2s}|\hat U_{\hat k}|^2 |k|^{d-1}$. A
comparison of exponents yields the result.) 

We can turn this around: Assume we are given a function $\hat u$ of unknown
smoothness. Let us compute its Fourier coefficients $\hat U_{\vec k}$
and see how fast they decay. If they decay as
@f[
	|\hat U_{\hat k}| = {\cal O}(|\vec k|^{-\mu-\epsilon}),
@f]
then consequently the function we had here was in $H^{\mu-d/2}$.


<h4>What we have to do</h4>

So what do we have to do to estimate the local smoothness of $u(x)$ on
a cell $K$? Clearly, the first step is to compute the Fourier series
of our solution. Fourier series being infinite series, we simplify our
task by only computing the first few terms of the series, such that
$|\vec k|\le N$ with a cut-off $N$. (Let us parenthetically remark
that we want to choose $N$ large enough so that we capture at least
the variation of those shape functions that vary the most. On the
other hand, we should not choose $N$ too large: clearly, a finite
element function, being a polynomial, is in $C^\infty$ on any given
cell, so the coefficients will have to decay exponentially at one
point; since we want to estimate the smoothness of the function this
polynomial approximates, not of the polynomial itself, we need to
choose a reasonable cutoff for $N$.) Either way, computing this series
is not particularly hard: from the definition
@f[
	\hat U_{\vec k}
	= \frac 1{(2\pi)^{d/2}} \int_{\hat K} e^{i\vec k \cdot \vec x} \hat u(\hat x) dx
@f]
we see that we can compute the coefficient $\hat U_{\vec k}$ as
@f[
	\hat U_{\vec k}
	= \frac 1{(2\pi)^{d/2}} 
          \sum_{i=0}^{\textrm{dofs per cell}}
          \left[\int_{\hat K} e^{i\vec k \cdot \vec x} \hat \varphi_i(\hat x)
	  dx \right] u_i,
@f]
where $u_i$ is the value of the $i$th degree of freedom on this
cell. In other words, we can write it as a matrix-vector product
@f[
	\hat U_{\vec k}
	= {\cal F}_{\vec k,i} u_i,
@f]
with the matrix
@f[
	{\cal F}_{\vec k,i}
	= \frac 1{(2\pi)^{d/2}} 
	\int_{\hat K} e^{i\vec k \cdot \vec x} \hat \varphi_i(\hat x) dx.
@f]
This matrix is easily computed for a given number of shape functions
$\varphi_i$ and Fourier modes $N$. Consequently, finding the
coefficients $\hat U_{\vec k}$ is a rather trivial job.

The next task is that we have to estimate how fast these coefficients
decay with $|\vec k|$. The problem is that, of course, we have only
finitely many of these coefficients in the first place. In other
words, the best we can do is to fit a function $\alpha |\vec
k|^{-\mu}$ to our data points $\hat U_{\vec k}$, for example by
determining $\alpha,\mu$ via a least-squares procedure:
@f[
	\min_{\alpha,\mu}
	\frac 12 \sum_{\vec k, |\vec k|\le N}
	\left( |\hat U_{\vec k}| - \alpha |\vec k|^{-\mu}\right)^2
@f]
However, the problem with this is that it leads to a nonlinear
problem, a fact that we would like to avoid. On the other hand, we can
transform the problem into a simpler one if we try to fit the
logarithm of our coefficients to the logarithm of $\alpha |\vec
k|^{-\mu}$, like this:
@f[
	\min_{\alpha,\mu}
	Q(\alpha,\mu) = 
	\frac 12 \sum_{\vec k, |\vec k|\le N}
	\left( \ln |\hat U_{\vec k}| - \ln (\alpha |\vec k|^{-\mu})\right)^2.
@f]
Using the usual facts about logarithms, we see that this yields the
problem 
@f[
	\min_{\beta,\mu}
	Q(\beta,\mu) = 
	\frac 12 \sum_{\vec k, |\vec k|\le N}
	\left( \ln |\hat U_{\vec k}| - \beta + \mu \ln |\vec k|\right)^2,
@f]
where $\beta=\ln \alpha$. This is now a problem for which the
optimality conditions $\frac{\partial Q}{\partial\beta}=0,
\frac{\partial Q}{\partial\mu}=0$, are linear in $\beta,\mu$. We can
write these conditions as follows:
@f[
	\left(\begin{array}{cc}
	\sum_{\vec k, |\vec k|\le N} 1 &
	\sum_{\vec k, |\vec k|\le N} \ln |\vec k| 
	\\
	\sum_{\vec k, |\vec k|\le N} \ln |\vec k| &
	\sum_{\vec k, |\vec k|\le N} (\ln |\vec k|)^2 
	\end{array}\right)
	\left(\begin{array}{c}
	\beta \\ -\mu
	\end{array}\right)
	=
	\left(\begin{array}{c}
	\sum_{\vec k, |\vec k|\le N} \ln |\hat U_{\vec k}|
	\\
	\sum_{\vec k, |\vec k|\le N} \ln |\hat U_{\vec k}| \ln |\vec k| 
	\end{array}\right)
@f]
This linear system is readily inverted to yield
@f[
	\beta = 
	\frac 1{\left(\sum_{\vec k, |\vec k|\le N} 1\right)
                \left(\sum_{\vec k, |\vec k|\le N} (\ln |\vec k|)^2\right)
		-\left(\sum_{\vec k, |\vec k|\le N} \ln |\vec k|\right)^2}
	\left[
	  \left(\sum_{\vec k, |\vec k|\le N} (\ln |\vec k|)^2\right)
	  \left(\sum_{\vec k, |\vec k|\le N} \ln |\hat U_{\vec k}|\right)
	  -
	  \left(\sum_{\vec k, |\vec k|\le N} \ln |\vec k|\right)
	  \left(\sum_{\vec k, |\vec k|\le N} \ln |\hat U_{\vec k}| \ln |\vec k| \right)
	\right]
@f]
and
@f[
	\mu = 
	\frac 1{\left(\sum_{\vec k, |\vec k|\le N} 1\right)
                \left(\sum_{\vec k, |\vec k|\le N} (\ln |\vec k|)^2\right)
		-\left(\sum_{\vec k, |\vec k|\le N} \ln |\vec k|\right)^2}
	\left[
	  \left(\sum_{\vec k, |\vec k|\le N} \ln |\vec k|\right)
	  \left(\sum_{\vec k, |\vec k|\le N} \ln |\hat U_{\vec k}|\right)
	  -
	  \left(\sum_{\vec k, |\vec k|\le N} 1\right)
	  \left(\sum_{\vec k, |\vec k|\le N} \ln |\hat U_{\vec k}| \ln |\vec k| \right)
	\right].
@f]

While we are not particularly interested in the actual value of
$\beta$, the formula above gives us a mean to calculate the value of
the exponent $\mu$ that we can then use to determine that $\hat u(\hat
x)$ is in $H^s(\hat K)$ with $s=\mu-\frac d2$.

