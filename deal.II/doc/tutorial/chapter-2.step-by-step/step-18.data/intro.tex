\documentclass{article}
\usepackage{amsmath}
\renewcommand{\vec}[1]{\mathbf{#1}}
\renewcommand{\div}{\mathrm{div}\ }
\begin{document}

This tutorial program is another one in the series on the elasticity problem
that we have already started with step-8 and step-17. It extends it into two
different directions: first, it solves the quasistatic but time dependent
elasticity problem for large deformations with a Lagrangian mesh movement
approach. Secondly, it shows some more techniques for solving such problems
using parallel processing with PETSc's linear algebra. In addition to this, we
show how to work around the main bottleneck of step-17, namely there that we
only generated graphical output from one process, and that this scaled very
badly with larger numbers of processes and on large problems. Finally, a good
number of assorted improvements and techniques are demonstrated that have not
been shown yet in previous programs.

As before in step-17, the program runs just as fine on a single sequential
machine as long as you have PETSc installed. Information on how to tell
deal.II about a PETSc installation on your system can be found in the deal.II
README file, which is linked to from the main documentation page
\texttt{doc/index.html} in your installation of deal.II, or on the deal.II
webpage \texttt{http://www.dealii.org/}.


\subsection*{Quasistatic elastic deformation}

\subsubsection*{Motivation of the model}

In general, small elastic deformations are described by the elastic wave
equation
\begin{gather*}
  \rho \frac{\partial^2 \vec u}{\partial t^2} 
  + c \frac{\partial \vec u}{\partial t}
  - \div ( C \varepsilon(\vec u)) = \vec f
  \qquad
  \text{in $\Omega$},
\end{gather*}
where $\vec u=\vec u (\vec x,t)$ is the deformation of the body, $\rho$ and
$c$ the density and attenuation coefficient, and $\vec f$ external forces. In
addition, initial conditions
\begin{align*}
  \vec u(\cdot, 0) = \vec u_0(\cdot)
  \qquad
  \text{on $\Omega$},
\end{align*}
and Dirichlet (displacement) or Neumann (force) boundary conditions need
to be specified for a unique solution:
\begin{align*}
  \vec u(\vec x,t) &= d(\vec x,t)
  \qquad
  &&\text{on $\Gamma_D\subset\partial\Omega$},  
  \\
  \vec n \ C \varepsilon(\vec u(\vec x,t)) &= b(\vec x,t)
  \qquad
  &&\text{on $\Gamma_N=\partial\Omega\backslash\Gamma_D$}.
\end{align*}
In above formulation, $\varepsilon(\vec u)= \tfrac 12 (\nabla \vec u + \nabla
\vec u^T)$ is the symmetric gradient of the displacement, also called the
\textit{strain}. $C$ is a tensor of rank 4, called the \textit{stress-strain
  tensor} that contains knowledge of the elastic strength of the material. We
will comment on the roles of the strain and stress tensors more below. For the
moment it suffices to say that we interpret the term $\div ( C
\varepsilon(\vec u))$ as the vector with components $\tfrac \partial{\partial
  x_j} C_{ijkl} \varepsilon(\vec u)_{kl}$, where summation over indices
$j,k,l$ is implied.

The quasistatic limit of this equation is motivated as follows: each small
perturbation of the body, for example by changes in boundary condition or the
forcing function, will result in a corresponding change in the configuration
of the body. In general, this will be in the form of waves radiating away from
the location of the disturbance. Due to the presence of the damping term,
these waves will be attenuated on a time scale of, say, $\tau$. Now, assume
that all changes in external configuration happen on times scales that are
much larger than $\tau$. In that case, the dynamic nature of the change is
unimportant: we can consider the body to always be in static equilibrium,
i.e. we can assume that at all times the body satisfies
\begin{align*}
  - \div ( C \varepsilon(\vec u)) &= \vec f
  &&\text{in $\Omega$},
  \\
  \vec u(\vec x,t) &= d(\vec x,t)
  \qquad
  &&\text{on $\Gamma_D$},
  \\
  \vec n \ C \varepsilon(\vec u(\vec x,t)) &= b(\vec x,t)
  \qquad
  &&\text{on $\Gamma_N$}.
\end{align*}
Note that the differential equation does not contain any time derivatives any
more -- all time dependence is introduced through boundary conditions and a
possibly time-varying force function $\vec f(\vec x,t)$.

While these equations are sufficient to describe small deformations, computing
large deformations is a little more complicated. To do so, let us first
introduce a stress variable $\sigma$, and write the differential equations in
terms of the stress:
\begin{align*}
  - \div \sigma &= \vec f
  &&\text{in $\Omega(t)$},
  \\
  \vec u(\vec x,t) &= d(\vec x,t)
  \qquad
  &&\text{on $\Gamma_D\subset\partial\Omega(t)$},
  \\
  \vec n \ C \varepsilon(\vec u(\vec x,t)) &= b(\vec x,t)
  \qquad
  &&\text{on $\Gamma_N=\partial\Omega(t)\backslash\Gamma_D$}.
\end{align*}
Note that these equations are posed on a domain $\Omega(t)$ that
changes with time, with the boundary moving according to the
displacements $\vec u(\vec x,t)$ of the points on the boundary. To
complete this system, we have to specify the relationship between the
stress and the strain, as follows:
\begin{align*}
  \dot\sigma = C \varepsilon (\dot{\vec u}),
\end{align*}
where a dot indicates a time derivative.


\subsubsection*{Time discretization}

Numerically, this system is solved as follows: first, we discretize
the time component using a backward Euler scheme. This leads to a
discrete equilibrium of force at time step $n$:
\begin{align*}
  \div \sigma^n &= f^n,
\intertext{where}
  \sigma^n &= \sigma^{n-1} + C \varepsilon (\Delta \vec u^n),
\end{align*}
and $\Delta \vec u^n$ the incremental displacement for time step
$n$. This way, if we want to solve for the displacement increment, we
have to solve the following system:
\begin{align*}
  - \div  C \varepsilon(\Delta\vec u^n) &= \vec f - \div \sigma^{n-1}
  &&\text{in $\Omega(t_{n-1})$},
  \\
  \Delta \vec u^n(\vec x,t) &= d(\vec x,t_n) - d(\vec x,t_{n-1})
  \qquad
  &&\text{on $\Gamma_D\subset\partial\Omega(t_{n-1})$},
  \\
  \vec n \ C \varepsilon(\Delta \vec u^n(\vec x,t)) &= b(\vec x,t_{1})-b(\vec x,t_{n-1})
  \qquad
  &&\text{on $\Gamma_N=\partial\Omega(t_{n-1})\backslash\Gamma_D$}.
\end{align*}
This system at time step $n$, to be solved on the old domain
$\Omega(t_{n-1})$, has exactly the form of a stationary elastic
problem, and is therefore similar to what we have already implemented
in previous example programs. We will therefore not comment on the
space discretization beyond saying that we again use lowest order
continuous finite elements.

There are differences, however:
\begin{enumerate}
  \item We have to move the mesh after each time step, in order to be
  able to solve the next time step on a new domain;

  \item We need to know $\sigma^{n-1}$ to compute the next incremental
  displacement, i.e. we need to compute it at the end of the time step
  to make sure it is available for the next time step. Essentially,
  the stress variable is our window to the history of deformation of
  the body.
\end{enumerate}
These two operations are done in the functions ``move\_mesh'' and
``update\_\-quadrature\_\-point\_history'' in the program. While moving
the mesh is only a technicality, updating the stress is a little more
complicated and will be discussed in the next section.


\subsubsection*{Updating the stress variable}
x

\subsection*{Parallel graphical output}

In the step-17 example program, the main bottleneck for parallel computations
was that only the first processor generated output for the entire domain.
Since generating graphical output is expensive, this did not scale well when
large numbers of processors were involved. However, no viable ways around this
problem were implemented in the library at the time, and the problem was
deferred to a later version.

This functionality has been implemented in the meantime, and this is the time
to explain its use. Basically, what we need to do is let every process
generate graphical output for that subset of cells that it owns, write them
into separate files and have a way to merge them later on. At this point, it
should be noted that none of the graphical output formats known to the author
of this program allows for a simple way to later re-read it and merge it with
other files corresponding to the same simulation. What deal.II therefore
offers is the following: When you call the ``DataOut::build\_patches''
function, an intermediate format is generated that contains all the
information for the data on each cell. Usually, this intermediate format is
then further processed and converted into one of the graphical formats that we
can presently write, such as gmv, eps, ucd, gnuplot, or a number of other
ones. Once written in these formats, there is no way to reconstruct the
necessary information to merge multiple blocks of output. However, the base
classes of ``DataOut'' also allows to simply dump the intermediate format to a
file, from which it can later be recovered without loss of information.

This has two advantages: first, simulations may just dump the intermediate
format data during run-time, and the user may later decide which particular
graphics format she wants to have. This way, she does not have to re-run the
entire simulation if graphical output is requested in a different format. One
typical case is that one would like to take a quick loook at the data with
gnuplot, and then create high-quality pictures using GMV or OpenDX. Since both
can be generated out of the intermediate format without problem, there is no
need to re-run the simulation.

In the present context, of more interest is the fact that in contrast to any
of the other formats, it is simple to merge multiple files of intermediate
format, if they belong to the same simulation. This is what we will do here:
we will generate one output file in intermediate format for each processor
that belongs to this computation (in the sequential case, this will simply be
a single file). They may then later be read in and merged so that we can
output a single file in whatever graphical format is requested.

The way to do this is to first instruct the ``DataOutBase'' class to
write intermediate format rather than in gmv or any other graphical
format. This is simple: just use
``data\_out.write\_deal\_II\_intermediate''. This will generate one file
called ``solution-TTTT.TTTT.d2'' if there is only one processor, or
files ``solution-TTTT.TTTT.NNN.d2'' if this is really a parallel
job. Here, ``TTTT.TTTT'' denotes the time for which this output has
been generated, and ``NNN'' the number of the MPI process that did this.

The next step is to convert this file or these files into whatever
format you like. For this, there is a program

HOW??


\end{document}
